{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b732f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing with True ω₀ = 1.00e+05 rad/s ---\n",
      "Loaded trained CNN model.\n",
      "\n",
      "RESULTS:\n",
      "True cutoff frequency (ω₀):      1.0000e+05 rad/s\n",
      "Predicted cutoff frequency (ω₀): 9.8626e+04 rad/s\n",
      "Error: 1.37%\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Testing with True ω₀ = 5.00e+03 rad/s ---\n",
      "Loaded trained CNN model.\n",
      "\n",
      "RESULTS:\n",
      "True cutoff frequency (ω₀):      5.0000e+03 rad/s\n",
      "Predicted cutoff frequency (ω₀): 4.9864e+03 rad/s\n",
      "Error: 0.27%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration (Should match your training script) ---\n",
    "NUM_FREQ_POINTS = 100\n",
    "DATA_FILE_PATH = f\"./RC_lowpass_data.npz\"\n",
    "MODEL_PATH = \"best_rc_model_cnn.pth\"\n",
    "\n",
    "# --- Re-define the Model and Dataset classes here for a standalone script ---\n",
    "# (You could also import them if your files are structured as a module)\n",
    "\n",
    "class CNN1D(nn.Module):\n",
    "    \"\"\"\n",
    "    The CNN model definition MUST match the one used for training.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_size):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=16, kernel_size=7, padding=3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=16, out_channels=32, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, NUM_FREQ_POINTS)\n",
    "            dummy_output = self.conv_layers(dummy_input)\n",
    "            flattened_size = dummy_output.shape[1] * dummy_output.shape[2]\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_layers(x)\n",
    "        return x\n",
    "\n",
    "class FunctionalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    We only need this class to easily get the mean and std from the training data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path):\n",
    "        data = np.load(data_path)\n",
    "        features_np = 20 * np.log10(data['X'] + 1e-8) if data['X'].max() > 1.0 else data['X']\n",
    "        features_np = features_np.astype(np.float32)\n",
    "        \n",
    "        self.features = torch.from_numpy(features_np).unsqueeze(1)\n",
    "        self.feature_mean = self.features.mean(dim=[0, 2], keepdim=True)\n",
    "        self.feature_std = self.features.std(dim=[0, 2], keepdim=True)\n",
    "\n",
    "    def get_scaling_params(self):\n",
    "        return self.feature_mean, self.feature_std\n",
    "\n",
    "# --- Main Test Function ---\n",
    "\n",
    "def test_single_frequency(omega0_true):\n",
    "    \"\"\"Tests the model with a single, known cutoff frequency.\"\"\"\n",
    "    \n",
    "    print(f\"--- Testing with True ω₀ = {omega0_true:.2e} rad/s ---\")\n",
    "\n",
    "    # 1. Load the model\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model not found at '{MODEL_PATH}'. Please train the model first.\")\n",
    "    \n",
    "    model = CNN1D(output_size=1)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    print(\"Loaded trained CNN model.\")\n",
    "\n",
    "    # 2. Get normalization parameters from the training dataset\n",
    "    if not os.path.exists(DATA_FILE_PATH):\n",
    "         raise FileNotFoundError(f\"Data file not found at '{DATA_FILE_PATH}'. Please generate it first.\")\n",
    "\n",
    "    # This part is a bit inefficient but ensures we use the exact same scaling\n",
    "    temp_dataset = FunctionalDataset(DATA_FILE_PATH)\n",
    "    feature_mean, feature_std = temp_dataset.get_scaling_params()\n",
    "\n",
    "    # 3. Generate the test frequency response\n",
    "    freqs = np.logspace(2, 6, num=NUM_FREQ_POINTS)\n",
    "    omega = 2 * np.pi * freqs\n",
    "    magnitude = np.abs(1 / (1 + 1j * (omega / omega0_true)))\n",
    "\n",
    "    # 4. Preprocess the input EXACTLY like the training data\n",
    "    # a) Convert to dB\n",
    "    magnitude_db = 20 * np.log10(magnitude + 1e-8)\n",
    "    \n",
    "    # b) Convert to tensor\n",
    "    input_tensor = torch.tensor(magnitude_db, dtype=torch.float32)\n",
    "    \n",
    "    # c) Add batch and channel dimensions for the CNN: (100,) -> (1, 1, 100)\n",
    "    input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # d) Normalize using the training set's mean and std\n",
    "    input_normalized = (input_tensor - feature_mean) / (feature_std + 1e-8)\n",
    "\n",
    "    # 5. Make the prediction\n",
    "    with torch.no_grad():\n",
    "        # The model predicts the LOG of omega0\n",
    "        predicted_log_omega0 = model(input_normalized)\n",
    "        \n",
    "        # We need to take the exponent to get the actual value\n",
    "        predicted_omega0 = torch.exp(predicted_log_omega0)\n",
    "\n",
    "    # 6. Print results\n",
    "    print(f\"\\nRESULTS:\")\n",
    "    print(f\"True cutoff frequency (ω₀):      {omega0_true:.4e} rad/s\")\n",
    "    print(f\"Predicted cutoff frequency (ω₀): {predicted_omega0.item():.4e} rad/s\")\n",
    "    \n",
    "    error_percent = 100 * abs(predicted_omega0.item() - omega0_true) / omega0_true\n",
    "    print(f\"Error: {error_percent:.2f}%\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Test with a frequency in the middle of our training range\n",
    "    test_omega0 = 1e5 \n",
    "    test_single_frequency(test_omega0)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "    # Test with a frequency near the lower end\n",
    "    test_omega0_low = 5e3\n",
    "    test_single_frequency(test_omega0_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c62e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
